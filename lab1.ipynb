{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First display the image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the image file\n",
    "image_path = './source_images/clouds.png'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "cv2.imshow('Image Window', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment I: \n",
    "\n",
    "Crop the image so it becomes square by chopping off the bottom part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image dimensions\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "side_length = min(height, width)\n",
    "\n",
    "x = (width - side_length) // 2\n",
    "y = (height - side_length) // 2\n",
    "\n",
    "square_image = image[y:y+side_length, x:x+side_length]\n",
    "\n",
    "cv2.imshow('Cropped Square Image', square_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment II:\n",
    "\n",
    "Discolor the image by reducing the intensity of the red value of every pixel by half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[:, :, 2] = image[:, :, 2] *0.5\n",
    "\n",
    "cv2.imshow('ReducedRedIntensity', square_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment III:\n",
    "\n",
    "Discolor the image by doubling the intensity of the red value of every pixel. You may have\n",
    "to handle an overflow problem (and use two more lines of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_channel = image[:, :, 2] * 2\n",
    "image[:, :, 2] = np.clip(red_channel, 0, 255)\n",
    "\n",
    "cv2.imshow('IncreaseRedIntensity', square_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment IV:\n",
    "\n",
    "Make a regular grid of black dots on the image so that the dots are 10 pixels apart vertically\n",
    "and horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[::10, ::10] = 0\n",
    "        \n",
    "cv2.imshow('RegularGrid', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding:\n",
    "\n",
    "Thresholding is a method to segment grayscale images. It can be used to find objects of interest in images. Pixel intensity values are compared to threshold value and classified according to wether they are higher or lower than this value. Finding the correct threshold is often not trivial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise II:\n",
    "\n",
    "Write a simple program to perform basic image thresholding on clouds.png. On simple images like this, a\n",
    "fixed threshold can be effective to separate foreground from background. The goal in this case is to achieve\n",
    "a binary image where the clouds are white and the empty sky is black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment V:\n",
    "\n",
    "Convert the image to grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Display the grayscale image\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment VI:\n",
    "\n",
    "Threshold the grayscale image at 50% of the maximum value for this datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, thresholded_image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment VII:\n",
    "\n",
    "Threshold the grayscale image at the ideal threshold determined by Otsu's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "otsu_threshold, thresholded_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Display the thresholded image\n",
    "cv2.imshow('Otsu Thresholded Image', thresholded_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3:\n",
    "\n",
    "Try your thresholding from the previous exercise on painting2.jpg. Clearly, a single threshold will not\n",
    "work to isolate the painting due to the intensity gradient present in the background. This can be addressed\n",
    "by adaptive thresholding: an appropriate threshold for each pixel can be determined based on the mean\n",
    "intensity in an area around the pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment VIII:\n",
    "\n",
    "Adaptively threshold the grayscale version of painting2.jpg so you get a similar result\n",
    "to the one below, where the background is uniformly white and you can cut out the painting along black\n",
    "lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the image\n",
    "image_path = './source_images/painting2.jpg'  # Make sure to use the correct path\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Directly load the image in grayscale\n",
    "\n",
    "# Apply adaptive thresholding to get a binary image\n",
    "thresholded_image = cv2.adaptiveThreshold(\n",
    "    image,\n",
    "    255,  # Value to assign if the condition is met\n",
    "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,  # Adaptive method\n",
    "    cv2.THRESH_BINARY,  # Threshold type\n",
    "    25,  # Block size (size of the neighbourhood area)\n",
    "    9# Constant subtracted from the mean\n",
    ")\n",
    "\n",
    "# Display the thresholded image\n",
    "cv2.imshow('Otsu Thresholded Image', thresholded_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV: Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment IX:\n",
    "\n",
    "A Gaussian filter replaces each pixel with a weighted average of the surrounding pixels. The weights in the\n",
    "kernel are determined by a 2D normal distribution around the central pixel, so nearby pixels have more\n",
    "influence than slightly more distant pixels. This type of filter is often used to remove white noise from the\n",
    "image. White noise is a form of noise in which each pixel has undergone a random deviation from its original\n",
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the white noise from whitenoise.png by Gaussian filtering. Find parameters for\n",
    "the Gaussian kernel that you find strike a good balance between noise level and blurriness of the result. This\n",
    "is subjective, but experiment with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./source_images/whitenoise.png')\n",
    "\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 3)\n",
    "\n",
    "# Display the thresholded image\n",
    "cv2.imshow('Otsu Thresholded Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Yes, in Gaussian filtering, the kernel size and the sigma (\n",
    "�\n",
    "σ) values of the Gaussian distribution can be chosen independently of each other, but there are practical considerations to keep in mind:\n",
    "\n",
    "Kernel Size\n",
    "Definition: The kernel size specifies the dimensions of the filter that is applied to the image. It must be an odd number (e.g., 3, 5, 7) to ensure there is a central pixel.\n",
    "Role: It determines the size of the neighborhood over which the Gaussian function is applied. A larger kernel size means that more neighboring pixels will influence the output pixel, resulting in more blurring.\n",
    "Sigma (\n",
    "�\n",
    "σ)\n",
    "Definition: Sigma values (\n",
    "�\n",
    "�\n",
    "σ \n",
    "X\n",
    "​\n",
    "  and \n",
    "�\n",
    "�\n",
    "σ \n",
    "Y\n",
    "​\n",
    " ) define the standard deviation of the Gaussian distribution in the horizontal and vertical directions, respectively.\n",
    "Role: They control how much the filter spreads out. Larger sigma values mean the filter will have a wider spread, affecting more distant pixels and thus producing more blurring.\n",
    "Independence and Interdependence\n",
    "Independence: Technically, you can choose the kernel size and sigma values without direct dependence on each other. For example, you can select a relatively large kernel size but with a small sigma value, or vice versa.\n",
    "Practical Interdependence: Although you can select these parameters independently, their chosen values should complement each other to achieve the desired filtering effect. A large kernel with too small a sigma might not effectively utilize the entire kernel size, as the weights far from the center will be very small. Conversely, a small kernel with a large sigma might not capture the full extent of the Gaussian distribution, potentially leading to less effective blurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment X: Test the gaussian filter on saltandpeppernoise.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('./source_images/saltandpeppernoise.png')\n",
    "\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 3)\n",
    "\n",
    "# Display the thresholded image\n",
    "cv2.imshow('Blurred Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment XI: Apply median filtering on the same image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread('./source_images/saltandpeppernoise.png')\n",
    "\n",
    "# Apply Median Blur\n",
    "# The second parameter is the aperture linear size; it must be odd and greater than 1, e.g., 3, 5, 7...\n",
    "median_blurred_image = cv2.medianBlur(image, 5)\n",
    "\n",
    "# Display the thresholded image\n",
    "cv2.imshow('Median Blurred Image', median_blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question III: Which result is preferable and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the median filter is a good choice for image processing because it indeed works better with outliers and the image does not become blurry. It can be used to remove noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Read the image\n",
    "image = cv2.imread('./source_images/unsharp.png')\n",
    "\n",
    "# Convert image to float32 for processing to prevent overflow\n",
    "image_float = np.float32(image)\n",
    "\n",
    "# Apply unsharp masking to the entire image\n",
    "# a. Blur the image\n",
    "blurred_image = cv2.GaussianBlur(image_float, (5, 5), 0)\n",
    "\n",
    "# b. Calculate the difference image (mask)\n",
    "difference_image = cv2.subtract(image_float, blurred_image)\n",
    "\n",
    "# d. Add the amplified difference to the original image to get the sharpened image\n",
    "sharpened_image = cv2.addWeighted(image_float, 1, difference_image, 10, 0)\n",
    "\n",
    "# Ensure the values are within the 0-255 range and convert back to uint8\n",
    "sharpened_image_uint8 = np.clip(sharpened_image, 0, 255).astype('uint8')\n",
    "\n",
    "# Step 2: Combine the original and sharpened images\n",
    "height, width, channels = image.shape\n",
    "midpoint = width // 2\n",
    "\n",
    "# Create a new image of the same size as the original in uint8\n",
    "combined_image = np.zeros_like(image)\n",
    "\n",
    "# Use the original image and the sharpened (and clipped) image for combination\n",
    "combined_image[:, :midpoint] = image[:, :midpoint]\n",
    "combined_image[:, midpoint:] = sharpened_image_uint8[:, midpoint:]\n",
    "\n",
    "# Display the combined image\n",
    "cv2.imshow('Combined Image', combined_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise VII\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('./source_images/blots.png')\n",
    "other_image = cv2.imread('./source_images/blots.png')\n",
    "\n",
    "# Define the custom kernel: a 15x15 matrix with a diagonal of 1s\n",
    "kernel = np.array([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "], dtype=float)\n",
    "\n",
    "# Scale the kernel by 1/7\n",
    "kernel_scaled = kernel * (1/7)\n",
    "\n",
    "# Apply the custom kernel using filter2D\n",
    "# -1 indicates that the depth of the output image is the same as the input\n",
    "diagonally_blurred_image = cv2.filter2D(image, -1, kernel_scaled)\n",
    "\n",
    "# Display the result code to view the image\n",
    "cv2.imshow('Diagonally Blurred Image', diagonally_blurred_image)\n",
    "cv2.imshow('Original Image', other_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve a similar diagonal blurring effect with an 8x8 kernel instead of a 15x15, you can use a kernel that has a diagonal of 1s, and then move the anchor point of the kernel. The anchor point in OpenCV is specified as a coordinate (x, y), where (0, 0) is the top-left corner of the kernel.\n",
    "\n",
    "For an 8x8 kernel, the default anchor point without specifying would be at the center, which is at coordinates (3, 3) for 0-indexed notation (since OpenCV uses 0-based indexing, the center of an 8x8 kernel is at position (3, 3), counting from 0).\n",
    "\n",
    "To simulate the effect of a larger kernel and achieve a similar diagonal blurring effect, you could move the anchor point to one of the corners. The choice of corner depends on the direction you want the blur effect to be emphasized.\n",
    "\n",
    "If you want to emphasize the blur in a bottom-right direction (similar to the effect of the original 15x15 kernel with a diagonal going from top-left to bottom-right), you could place the anchor at the top-left corner of the 8x8 kernel, which is at coordinates (0, 0).\n",
    "Conversely, if you wanted to emphasize the blur in a top-right direction, you could move the anchor to the bottom-left corner, which would be at coordinates (0, 7) in 0-indexed notation.\n",
    "However, to directly replicate the effect of the original kernel with its diagonal from the top-left to the bottom-right of the kernel, you would place the anchor at the top-left. This setup assumes the blur effect is intended to propagate in a direction consistent with the placement of the 1s in the kernel, relative to the anchor point.\n",
    "\n",
    "Given this, for an 8x8 kernel to mimic the effect of the original 15x15 kernel by adjusting the anchor point, you would specify the anchor point at (0, 0) to start the blur effect from the top-left corner of the kernel, moving across the image diagonally.\n",
    "\n",
    "It's important to note, though, that moving the anchor point changes how the kernel is applied to the image but does not change the kernel's shape or inherent properties. It shifts the \"center\" of the operation to a different part of the kernel, which can affect the resulting image in specific ways depending on your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('./source_images/blots.png')\n",
    "other_image = cv2.imread('./source_images/blots.png')\n",
    "\n",
    "kernel_8_8 =  kernel_scaled[:8, :8]\n",
    "anchor = (7,7)\n",
    "# Apply the custom kernel using filter2D\n",
    "# -1 indicates that the depth of the output image is the same as the input\n",
    "diagonally_blurred_image_2 = cv2.filter2D(image, -1, kernel_8_8, anchor=anchor)\n",
    "\n",
    "# Display the result code to view the image\n",
    "cv2.imshow('Blurred Image', diagonally_blurred_image)\n",
    "cv2.imshow('Diagonally Blurred Image', diagonally_blurred_image_2)\n",
    "cv2.imshow('Original Image', other_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
